{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataframe (assuming it's already sorted by location and date_utc)\n",
    "df = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/air_quality_imputed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time based features\n",
    "df[\"date_utc\"] = pd.to_datetime(df[\"date_utc\"])\n",
    "df[\"day_of_week\"] = df[\"date_utc\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"date_utc\"].dt.month\n",
    "df[\"hour\"] = df[\"date_utc\"].dt.hour\n",
    "\n",
    "# Create rolling averages of pollution concentrations\n",
    "pollutants = [\"co\", \"no2\", \"o3\", \"pm10\", \"pm25\", \"so2\"]\n",
    "window_size = 24\n",
    "\n",
    "for pollutant in pollutants:\n",
    "    df[f\"{pollutant}_rolling_mean\"] = df.groupby(\"location\")[pollutant].transform(lambda x: x.rolling(window=window_size).mean())\n",
    "\n",
    "# Create difference from rolling average and current value\n",
    "for pollutant in pollutants:\n",
    "    df[f\"{pollutant}_diff_from_mean\"] = df[pollutant] - df[f\"{pollutant}_rolling_mean\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_utc                 0\n",
       "location                 0\n",
       "latitude                 0\n",
       "longitude                0\n",
       "co                       0\n",
       "no2                      0\n",
       "o3                       0\n",
       "pm10                     0\n",
       "pm25                     0\n",
       "so2                      0\n",
       "day_of_week              0\n",
       "month                    0\n",
       "hour                     0\n",
       "co_rolling_mean        138\n",
       "no2_rolling_mean       138\n",
       "o3_rolling_mean        138\n",
       "pm10_rolling_mean      138\n",
       "pm25_rolling_mean      138\n",
       "so2_rolling_mean       138\n",
       "co_diff_from_mean      138\n",
       "no2_diff_from_mean     138\n",
       "o3_diff_from_mean      138\n",
       "pm10_diff_from_mean    138\n",
       "pm25_diff_from_mean    138\n",
       "so2_diff_from_mean     138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for Nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Impute missing values using KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X = df.drop(['date_utc', 'location', 'latitude', 'longitude', 'pm25'], axis=1)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "y = df['pm25']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Evaluation:\n",
      "Mean Squared Error: 1.4218364126986636\n",
      "Mean Absolute Error: 0.0337162324398716\n",
      "R^2 Score: 0.9999595555725649\n",
      "-------------------------\n",
      "Random Forest Evaluation:\n",
      "Mean Squared Error: 247.67519923549386\n",
      "Mean Absolute Error: 0.8082761317944359\n",
      "R^2 Score: 0.9929548283237865\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'{model_name} Evaluation:')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'R^2 Score: {r2}')\n",
    "    print('-------------------------')\n",
    "\n",
    "evaluate_model(y_test, lr_pred, 'Linear Regression')\n",
    "evaluate_model(y_test, rf_pred, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (Cross-Validation) - Average MSE: 8.296784272436494, Average R^2: 0.9993931157337567\n",
      "Random Forest (Cross-Validation) - Average MSE: 3404.4070609488526, Average R^2: 0.9540676122937581\n"
     ]
    }
   ],
   "source": [
    "# Perform cross validation to better assess model performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_cv_scores = cross_val_score(lr_model, X_imputed, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_cv_scores = cross_val_score(rf_model, X_imputed, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "lr_avg_mse = -lr_cv_scores.mean()\n",
    "rf_avg_mse = -rf_cv_scores.mean()\n",
    "\n",
    "lr_avg_r2 = cross_val_score(lr_model, X_imputed, y, cv=5, scoring='r2').mean()\n",
    "rf_avg_r2 = cross_val_score(rf_model, X_imputed, y, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(f'Linear Regression (Cross-Validation) - Average MSE: {lr_avg_mse}, Average R^2: {lr_avg_r2}')\n",
    "print(f'Random Forest (Cross-Validation) - Average MSE: {rf_avg_mse}, Average R^2: {rf_avg_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value: 1\n",
      "Best negative mean squared error: -1.3418841693832089\n",
      "Lasso Regression Evaluation:\n",
      "Mean Squared Error: 1.0099235464645562\n",
      "Mean Absolute Error: 0.026232031069316944\n",
      "R^2 Score: 0.9999712725182551\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up Lasso Regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Set up a range of alpha values for hyperparameter tuning\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# Set up a dictionary for the grid search\n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "# Set up GridSearchCV with Lasso Regression model, using 5-fold cross-validation and neg_mean_squared_error as the scoring metric\n",
    "grid_search = GridSearchCV(lasso_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit GridSearchCV to the imputed data\n",
    "grid_search.fit(X_imputed, y)\n",
    "\n",
    "# Get the best alpha value and corresponding negative mean squared error\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_neg_mse = grid_search.best_score_\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best alpha value: {best_alpha}\")\n",
    "print(f\"Best negative mean squared error: {best_neg_mse}\")\n",
    "\n",
    "# Train Lasso Regression model with the best alpha value\n",
    "best_lasso_model = Lasso(alpha=best_alpha)\n",
    "best_lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lasso_pred = best_lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(y_test, lasso_pred, 'Lasso Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
