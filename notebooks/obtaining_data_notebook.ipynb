{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 29\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     status, resp \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mmeasurements(city\u001b[39m=\u001b[39;49mcity, parameter\u001b[39m=\u001b[39;49mparameter, limit\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m, page\u001b[39m=\u001b[39;49mpage, date_from\u001b[39m=\u001b[39;49mcurrent_start_date, date_to\u001b[39m=\u001b[39;49mcurrent_end_date)\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m \u001b[39mand\u001b[39;00m resp[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/decorators.py:87\u001b[0m, in \u001b[0;36mpandasize.<locals>.decorator.<locals>.decorated_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:418\u001b[0m, in \u001b[0;36mOpenAQ.measurements\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\"\"\"Provides data about individual measurements\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[39m:param city: Limit results by a certain city. Defaults to ``None``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m}\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(\u001b[39m'\u001b[39;49m\u001b[39mmeasurements\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:84\u001b[0m, in \u001b[0;36mAPI._get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send(url, \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:71\u001b[0m, in \u001b[0;36mAPI._send\u001b[0;34m(self, endpoint, method, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mraise\u001b[39;00m ApiError(\u001b[39m\"\u001b[39m\u001b[39mA bad request was made: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(resp\u001b[39m.\u001b[39mstatus_code))\n\u001b[1;32m     73\u001b[0m res \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mApiError\u001b[0m: A bad request was made: 500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     40\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError encountered: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. Retrying in 60 seconds.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m                 time\u001b[39m.\u001b[39;49msleep(\u001b[39m60\u001b[39;49m)\n\u001b[1;32m     43\u001b[0m         current_start_date \u001b[39m=\u001b[39m current_end_date\n\u001b[1;32m     45\u001b[0m \u001b[39m# Merge data from all parameters\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try to get 10 years of pollution data for Dehli from OpenAQ API\n",
    "\n",
    "import openaq\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Initialize OpenAQ API client\n",
    "api = openaq.OpenAQ()\n",
    "\n",
    "# Fetch data for Delhi\n",
    "city = 'Delhi'\n",
    "parameters = ['pm25', 'pm10', 'o3', 'co', 'so2', 'no2']\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365 * 10)  # 10 years ago\n",
    "\n",
    "for parameter in parameters:\n",
    "    current_start_date = start_date\n",
    "    while current_start_date < end_date:\n",
    "        current_end_date = current_start_date + timedelta(days=31)\n",
    "        if current_end_date > end_date:\n",
    "            current_end_date = end_date\n",
    "        \n",
    "        has_more_data = True\n",
    "        page = 1\n",
    "        while has_more_data:\n",
    "            try:\n",
    "                status, resp = api.measurements(city=city, parameter=parameter, limit=10000, page=page, date_from=current_start_date, date_to=current_end_date)\n",
    "                if status == 200 and resp['results']:\n",
    "                    df = pd.DataFrame(resp['results'])\n",
    "                    data_frames.append(df)\n",
    "                    if len(df) < 10000:\n",
    "                        has_more_data = False\n",
    "                    else:\n",
    "                        page += 1\n",
    "                else:\n",
    "                    has_more_data = False\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered: {e}. Retrying in 60 seconds.\")\n",
    "                time.sleep(60)\n",
    "\n",
    "        current_start_date = current_end_date\n",
    "\n",
    "# Merge data from all parameters\n",
    "merged_data = pd.concat(data_frames, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get data by year as was getting errors trying to request a full 10 years of data at once\n",
    "\n",
    "def fetch_data_for_year(city, parameters, start_year):\n",
    "    api = openaq.OpenAQ()\n",
    "    year_data_frames = []\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        current_start_date = datetime(start_year, month, 1)\n",
    "        current_end_date = datetime(start_year, month + 1, 1) if month < 12 else datetime(start_year + 1, 1, 1)\n",
    "        \n",
    "        for parameter in parameters:\n",
    "            has_more_data = True\n",
    "            page = 1\n",
    "            \n",
    "            while has_more_data:\n",
    "                try:\n",
    "                    status, resp = api.measurements(city=city, parameter=parameter, limit=10000, page=page, date_from=current_start_date, date_to=current_end_date)\n",
    "                    if status == 200 and resp['results']:\n",
    "                        df = pd.DataFrame(resp['results'])\n",
    "                        year_data_frames.append(df)\n",
    "                        if len(df) < 10000:\n",
    "                            has_more_data = False\n",
    "                        else:\n",
    "                            page += 1\n",
    "                    else:\n",
    "                        has_more_data = False\n",
    "                except Exception as e:\n",
    "                    print(f\"Error encountered: {e}. Retrying in 60 seconds.\")\n",
    "                    time.sleep(60)\n",
    "    \n",
    "    year_data = pd.concat(year_data_frames, axis=0)\n",
    "    return year_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters we will be reusing for every year \n",
    "city = 'Delhi'\n",
    "parameters = ['pm25', 'pm10', 'o3', 'co', 'so2', 'no2']\n",
    "\n",
    "# get data for 2015\n",
    "year_2015_data = fetch_data_for_year(city, parameters, 2015)\n",
    "year_2015_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2015_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for 2016\n",
    "year_2016_data = fetch_data_for_year(city, parameters, 2016)\n",
    "year_2016_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2016_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for 2017\n",
    "year_2017_data = fetch_data_for_year(city, parameters, 2017)\n",
    "year_2017_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2017_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2018_data = fetch_data_for_year(city, parameters, 2018)\n",
    "year_2018_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2018_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2019_data = fetch_data_for_year(city, parameters, 2019)\n",
    "year_2019_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2019_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2020_data = fetch_data_for_year(city, parameters, 2020)\n",
    "year_2020_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2020_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2021_data = fetch_data_for_year(city, parameters, 2021)\n",
    "year_2021_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2021_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n",
      "Error encountered: A bad request was made: 500. Retrying in 60 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 20\u001b[0m, in \u001b[0;36mfetch_data_for_year\u001b[0;34m(city, parameters, start_year)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     status, resp \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mmeasurements(city\u001b[39m=\u001b[39;49mcity, parameter\u001b[39m=\u001b[39;49mparameter, limit\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m, page\u001b[39m=\u001b[39;49mpage, date_from\u001b[39m=\u001b[39;49mcurrent_start_date, date_to\u001b[39m=\u001b[39;49mcurrent_end_date)\n\u001b[1;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m \u001b[39mand\u001b[39;00m resp[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/decorators.py:87\u001b[0m, in \u001b[0;36mpandasize.<locals>.decorator.<locals>.decorated_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:418\u001b[0m, in \u001b[0;36mOpenAQ.measurements\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\"\"\"Provides data about individual measurements\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[39m:param city: Limit results by a certain city. Defaults to ``None``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m}\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(\u001b[39m'\u001b[39;49m\u001b[39mmeasurements\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:84\u001b[0m, in \u001b[0;36mAPI._get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send(url, \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/lighthouse_labs_env/lib/python3.10/site-packages/openaq/__init__.py:71\u001b[0m, in \u001b[0;36mAPI._send\u001b[0;34m(self, endpoint, method, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mraise\u001b[39;00m ApiError(\u001b[39m\"\u001b[39m\u001b[39mA bad request was made: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(resp\u001b[39m.\u001b[39mstatus_code))\n\u001b[1;32m     73\u001b[0m res \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mApiError\u001b[0m: A bad request was made: 500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m year_2022_data \u001b[39m=\u001b[39m fetch_data_for_year(city, parameters, \u001b[39m2022\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m year_2022_data\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2022_data.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[56], line 32\u001b[0m, in \u001b[0;36mfetch_data_for_year\u001b[0;34m(city, parameters, start_year)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     31\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError encountered: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. Retrying in 60 seconds.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m                 time\u001b[39m.\u001b[39;49msleep(\u001b[39m60\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m year_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(year_data_frames, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mreturn\u001b[39;00m year_data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year_2022_data = fetch_data_for_year(city, parameters, 2022)\n",
    "year_2022_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2022_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Error: A bad request was made: 500. Retrying in 60 seconds. Retry 1 of 5.\n",
      "Error encountered for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Error: A bad request was made: 500. Retrying in 60 seconds. Retry 2 of 5.\n",
      "Error encountered for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Error: A bad request was made: 500. Retrying in 60 seconds. Retry 3 of 5.\n",
      "Error encountered for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Error: A bad request was made: 500. Retrying in 60 seconds. Retry 4 of 5.\n",
      "Error encountered for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Error: A bad request was made: 500. Retrying in 60 seconds. Retry 5 of 5.\n",
      "Max retries reached for Delhi, co, 2022-01-01 00:00:00, 2022-01-31 00:00:00, Page: 1. Skipping and moving to next.\n"
     ]
    }
   ],
   "source": [
    "# issues getting 2022 data as a full so will get by month and concatenate\n",
    "\n",
    "def fetch_data_for_year2(city, parameters, start_year):\n",
    "    api = openaq.OpenAQ()\n",
    "    data_frames = []\n",
    "\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(start_year + 1, 1, 1)\n",
    "\n",
    "    for parameter in parameters:\n",
    "        current_date = start_date\n",
    "        while current_date < end_date:\n",
    "            current_start_date = current_date\n",
    "            current_end_date = min(current_date + timedelta(days=30), end_date)\n",
    "\n",
    "            has_more_data = True\n",
    "            page = 1\n",
    "\n",
    "            while has_more_data:\n",
    "                max_retries = 5\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    try:\n",
    "                        status, resp = api.measurements(city=city, parameter=parameter, limit=10000, page=page, date_from=current_start_date, date_to=current_end_date)\n",
    "                        if status == 200 and resp['results']:\n",
    "                            df = pd.DataFrame(resp['results'])\n",
    "                            data_frames.append(df)\n",
    "                            if len(df) < 10000:\n",
    "                                has_more_data = False\n",
    "                            else:\n",
    "                                page += 1\n",
    "                        else:\n",
    "                            has_more_data = False\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        retry_count += 1\n",
    "                        print(f\"Error encountered for {city}, {parameter}, {current_start_date}, {current_end_date}, Page: {page}. Error: {e}. Retrying in 60 seconds. Retry {retry_count} of {max_retries}.\")\n",
    "                        time.sleep(60)\n",
    "\n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"Max retries reached for {city}, {parameter}, {current_start_date}, {current_end_date}, Page: {page}. Skipping and moving to next.\")\n",
    "                    break\n",
    "\n",
    "            current_date += timedelta(days=30)\n",
    "\n",
    "    merged_data = pd.concat(data_frames, axis=0)\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "city = 'Delhi'\n",
    "parameters = ['pm25', 'pm10', 'o3', 'co', 'so2', 'no2']\n",
    "start_year = 2022\n",
    "\n",
    "year_2022_data = fetch_data_for_year2(city, parameters, start_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2022_data.to_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2022_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each CSV file\n",
    "data_2015 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2015_data.csv')\n",
    "data_2016 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2016_data.csv')\n",
    "data_2017 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2017_data.csv')\n",
    "data_2018 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2018_data.csv')\n",
    "data_2019 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2019_data.csv')\n",
    "data_2020 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2020_data.csv')\n",
    "data_2021 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2021_data.csv')\n",
    "data_2022 = pd.read_csv('/Users/magnesium/Documents/Light House Labs Bootcamp/Projects/Final Project/data/year_2022_data.csv')\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_data = pd.concat([data_2015, data_2016, data_2017, data_2018, data_2019, data_2020, data_2021, data_2022], axis=0)\n",
    "\n",
    "# Save the combined DataFrame as a new CSV file\n",
    "combined_data.to_csv('combined_data_2015_2022.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5432000, 8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape # HUGE DATAFRAME! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
